　　【作品名称】禁止进攻型全面自主武器（杀手机器人）的必要性及可行性调查和研究
【关键字】AI技术，
【作品简介】	
　　进攻型全面自主武器（杀手机器人）作为自主性强，危险性高，隐蔽性好的未来武器，已经随着AI及机器人技术的发展，变为随时可能实现的武器。
　　能够自主决策的自动化杀手机器人不但将完全改变未来战争的面貌，而且将对伦理道德，国家安全和人身安全造成极大冲击。
　　通过调研国内外群众对于智能武器的认识水平，各国NGO对禁止智能武器所做的努力，以及智能武器的发展现状及可能应用，来说明禁止其的必要性及可行性。
　　
　　我们准备从以下四个方面开展研究：
1. 目前和将来发展情况及可能应用：  AI科技方面
2. 国内外对此重视程度及进展：  社会学方向
3. 智能武器对国家安全和人身安全（人权）的影响：国际关系法方向
4. 如何推动立法有效限制智能武器使用：  NGO非政府组织（主要作用是推进人们意识提升）
　　
　　我们现阶段认为的必要性：
1. 大规模使用Killer Robot导致战争规模升级,可能落入对方手中，甚至落入恐怖分子手中；各国家进行军备竞赛，
2. 研究机构进行快速而不严谨不安全的研究，这种机器人可能出故障或者被黑入，造成不堪设想的后果。
3. 机器人分辨军事目标和民众的技术并不容易做出来，可能误伤。
4. 一些国家提出未来战争是机器人之间的战争，这是不可能的，战争在我们身边发生，没有分离的战争世界
　　
以及可行性：
　　只要武器研发公司和国家认同禁令，武器禁止就会有显著效果。可以借鉴曾经有的成功案例，比如1997年的禁止反单兵地雷使用以及禁止激光致盲武器的研发和使用，都取得了显著的成果。进一步我们将调研智能武器和核武器，生物武器等之间的区别和联系，从而预防智能武器可能造成的毁灭性后果。
　　注：作品简介篇幅不得超过A4纸1页，可附图不超过1张。作品简介、正式文档以及作品视频中不得以任何形式（文字、照片、视频）体现院系、作者或指导老师的信息。
　　清华大学第三十六届“挑战杯”学生课外学术科技作品竞赛参赛作品简介
　　
　　1
　　
